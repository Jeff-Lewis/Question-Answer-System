{
    "contents" : "#IEMS 395 Text Mining\n#Nick Paras\nlibrary(tm)\n#library(plyr)\nlibrary(openNLP)\nrequire(\"NLP\")\nlibrary(SnowballC)\n#library(RWeka)\n\n# function to initialize the openNLP annotation functions\ninitOpenNLP <- function() {\n  #initialize openNLP fcns to do part of speech / sentence tagging\n  sent_token_annotator <- Maxent_Sent_Token_Annotator()\n  word_token_annotator <- Maxent_Word_Token_Annotator()\n  pos_tag_annotator <- Maxent_POS_Tag_Annotator()\n}\n\n\n#Load the corpus\nallFiles = DirSource(\"reformattedPostings\",\"CP1252\")\ncorp = Corpus(allFiles,readerControl = list(language=\"en\"))\n\n#Make an unprocessed corpus for sentence selection\ncorpSen = Corpus(allFiles,readerControl = list(language=\"en\"))\n\n# function to perform preprocessing on a corpus\npreProc <- function(corpusObj) {\n  corpusObj <- tm_map(corpusObj, removePunctuation)\n  corpusObj <- tm_map(corpusObj, removeWords, stopwords(\"english\"))\n  corpusObj <- tm_map(corpusObj, stripWhitespace)\n  corpusObj <- tm_map(corpusObj, stemDocument)\n}\n\n\n#options(mc.cores=1)\n#CustomTokenizer <- function(x) {RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 1, max = 1))}\n#dtm2 <- DocumentTermMatrix(corp, control = list(tokenize = CustomTokenizer))\n#options(mc.cores=4)\n\n#create documentTermMatrix\ndtm = DocumentTermMatrix(corp)\n\n# function to extract type from the query\ngetQueryType <- function(query) {\n  if (grepl(\"CEO\",query)) {\n    qType = \"Query Type: CEO\"\n  } else if (grepl(\"bankrupt\",query)) {\n    qType = \"Query Type: bankruptcy\"\n  } else if (grepl(\"GDP\",query)) {\n    qType = \"Query Type: GDP\"\n  } else if (grepl(\"percentage\",query)) {\n    qType = \"Query Type: percentage\"\n  } else {\n    qType = \"Invalid query, please try again\"\n  }\n  return(qType)\n}\n\n# function to extract keywords from the queries\ngetKeywords <- function(query) {\n  library(sqldf)\n  keyPosDict = data.frame(tags=c(\"NNP\", \"NNPS\", \"NN\", \"NNS\", \"JJ\", \"JJR\", \"JJS\", \"CD\"))\n  ## Need sentence and word token annotations.\n  a2 <- annotate(query, list(sent_token_annotator, word_token_annotator))\n  a3 <- annotate(query, pos_tag_annotator, a2)\n  a3w <- (subset(a3, type == \"word\"))\n  a4 = data.frame(a3w)[,1:4]\n  for (row in 1:nrow(a4)) {\n    a4$tag[row] = data.frame(a3w)$features[[row]]$POS \n  }\n  keys = sqldf('select * from a4 where tag in (select * from keyPosDict);')\n  for (row in 1:nrow(keys)) {\n    keys$token[row] = substr(query,keys$start[row],keys$end[row])\n  }\n  return(keys$token)\n}\n\n# function to extract documents with at least 1 keyword match\ngetDocuments <- function(keywords, docTermMat) {\n  \n  #stem the keywords \n  keywords = wordStem(keywords)\n  \n  #find the tokens/columns of the DTM that contain the keywords\n  locTok = sapply(keywords, function(x) colnames(docTermMat)[grepl(tolower(x),colnames(docTermMat))])\n  locTok = as.character(c(unlist(locTok)))\n  tokCol = c(which(colnames(docTermMat) %in% locTok))\n  \n  #find the documents that have at least 1 of they keywords/similar keyword matches\n  docInd = apply(docTermMat[,tokCol],1,function(x) sum(x) > 0)\n  return(docInd)\n}\n\n# function to score and sort documents by TF-IDF on keywords\nscoreDocuments <- function(keywords, redDocTermMat) {\n  \n}\n\n# function to extract a vector of sentences from a document\ngetSentences <- function(text) {\n  ## Need sentence and word token annotations.\n  a2 <- annotate(text, list(sent_token_annotator))\n  for (ind in 1:length(a2))  {\n    if (ind == 1) {\n      sent = substr(text, a2$start[ind], a2$end[ind])\n    } else {\n      sent = c(sent, substr(text, a2$start[ind], a2$end[ind]))\n    }\n  }\n  return(sent)\n}\n\n# function to make new corpus out of sentences\ngetSentCorp <- function(sentVec) {\n  \n}\n\n",
    "created" : 1425587927829.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2842827024",
    "id" : "C84D28BB",
    "lastKnownWriteTime" : 1426034287,
    "path" : "~/Documents/IEMS_395_HW4/sourceCode.R",
    "project_path" : "sourceCode.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}