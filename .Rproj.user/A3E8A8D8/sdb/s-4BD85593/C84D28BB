{
    "contents" : "#IEMS 395 Text Mining\n#Nick Paras\nlibrary(tm)\n#library(plyr)\nlibrary(openNLP)\nrequire(\"NLP\")\nlibrary(SnowballC)\n#library(RWeka)\n\n\n#initialize openNLP fcns to do part of speech / sentence tagging\nsent_token_annotator <- Maxent_Sent_Token_Annotator()\nword_token_annotator <- Maxent_Word_Token_Annotator()\npos_tag_annotator <- Maxent_POS_Tag_Annotator()\n\n#Load the corpus\nallFiles = DirSource(\"reformattedPostings\",\"CP1252\")\ncorp = Corpus(allFiles,readerControl = list(language=\"en\"))\n\n#Make an unprocessed corpus for sentence selection\ncorpSen = Corpus(allFiles,readerControl = list(language=\"en\"))\n\n#preprocessing\ncorp <- tm_map(corp, removePunctuation)\ncorp <- tm_map(corp, removeWords, stopwords(\"english\"))\ncorp <- tm_map(corp, stripWhitespace)\ncorp <- tm_map(corp, stemDocument)\n\n#CustomTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 3))\n#options(mc.cores=1)\n#CustomTokenizer <- function(x) {RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 1, max = 1))}\n#dtm2 <- DocumentTermMatrix(corp, control = list(tokenize = CustomTokenizer))\ndtm = DocumentTermMatrix(corp)\n#options(mc.cores=4)\n\n\n# function to extract type from the query\ngetQueryType <- function(query) {\n  if (grepl(\"CEO\",query)) {\n    qType = \"Query Type: CEO\"\n  } else if (grepl(\"bankrupt\",query)) {\n    qType = \"Query Type: bankruptcy\"\n  } else if (grepl(\"GDP\",query)) {\n    qType = \"Query Type: GDP\"\n  } else if (grepl(\"percentage\",query)) {\n    qType = \"Query Type: percentage\"\n  } else {\n    qType = \"Invalid query, please try again\"\n  }\n  return(qType)\n}\n\n# function to extract keywords from the queries\ngetKeywords <- function(query) {\n  library(sqldf)\n  keyPosDict = data.frame(tags=c(\"NNP\", \"NNPS\", \"NN\", \"NNS\", \"JJ\", \"JJR\", \"JJS\", \"CD\"))\n  ## Need sentence and word token annotations.\n  a2 <- annotate(query, list(sent_token_annotator, word_token_annotator))\n  a3 <- annotate(query, pos_tag_annotator, a2)\n  a3w <- (subset(a3, type == \"word\"))\n  a4 = data.frame(a3w)[,1:4]\n  for (row in 1:nrow(a4)) {\n    a4$tag[row] = data.frame(a3w)$features[[row]]$POS \n  }\n  keys = sqldf('select * from a4 where tag in (select * from keyPosDict);')\n  for (row in 1:nrow(keys)) {\n    keys$token[row] = substr(query,keys$start[row],keys$end[row])\n  }\n  return(keys$token)\n}\n\n# function to extract documents with at least 1 keyword match\n\n\n\n\n\n# function to extract a vector of sentences from a document\ngetSentences <- function(text) {\n  ## Need sentence and word token annotations.\n  a2 <- annotate(text, list(sent_token_annotator))\n  for (ind in 1:length(a2))  {\n    if (ind == 1) {\n      sent = substr(text, a2$start[ind], a2$end[ind])\n    } else {\n      sent = c(sent, substr(text, a2$start[ind], a2$end[ind]))\n    }\n  }\n  return(sent)\n}",
    "created" : 1425587927829.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3800214230",
    "id" : "C84D28BB",
    "lastKnownWriteTime" : 1425960076,
    "path" : "~/Documents/IEMS_395_HW4/sourceCode.R",
    "project_path" : "sourceCode.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}