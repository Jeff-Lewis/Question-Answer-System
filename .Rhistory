}
return(finalKeys)
}
questionAnswer("what affects GDP?")
questionAnswer("what percentage is associated with personal consumption")
# function to score sentences
scoreSentences <- function(keywords, docTermMat, cleanCorp) {
#stem the keywords
keywords = wordStem(keywords)
#compute number of shared tokens
#find tokens that are not count = 0 in each document
#sentTerms = apply(docTermMat,1, function(x) colnames(x)[which(!x == 0)])
#give tfidf weightings
tfidfMat = weightSMART(docTermMat,spec="apc")
#tfidfMat = weightTfIdf(docTermMat,normalize = TRUE)
#find the tokens/columns of the DTM that contain the keywords
locTok = sapply(keywords, function(x) colnames(docTermMat)[grepl(tolower(x),colnames(docTermMat))])
#locTok = sapply(keywords, function(x) colnames(docTermMat)[which(tolower(x) %in% colnames(docTermMat))])
locTok = as.character(c(unlist(locTok)))
tokCol = c(which(colnames(docTermMat) %in% locTok))
docMatLen = length(tokCol)
#compute tfidf score for each document
docScoreMatches = apply(tfidfMat[,tokCol],1,function(x) sum(x) )
docScoreNonMatches = apply(tfidfMat[,-tokCol],1,function(x) sum(x) )
docScore = 5 * docMatLen +  2 * docScoreMatches - docScoreNonMatches;
docRank = sort(docScore,decreasing=TRUE)
#return top ten scoring documents
return(docRank[1:40])
}
questionAnswer("what affects GDP?")
# function to add additional keywords based on question type for more robust answers
augKey <- function(keys, type) {
#initialize return variable
finalKeys = keys
if (type == "gdp") {
finalKeys = c(finalKeys, "factors", "components", "%", "percent")# "growth")
#finalKeys = c(finalKeys, "factors", "components", "%", "percent", "growth")
}
return(finalKeys)
}
questionAnswer("what affects GDP?")
# function to add additional keywords based on question type for more robust answers
augKey <- function(keys, type) {
#initialize return variable
finalKeys = keys
if (type == "gdp") {
finalKeys = c(finalKeys, "factors", "components", "%", "percent", "growth")
}
return(finalKeys)
}
# function to score sentences
scoreSentences <- function(keywords, docTermMat, cleanCorp) {
#stem the keywords
keywords = wordStem(keywords)
#compute number of shared tokens
#find tokens that are not count = 0 in each document
#sentTerms = apply(docTermMat,1, function(x) colnames(x)[which(!x == 0)])
#give tfidf weightings
tfidfMat = weightSMART(docTermMat,spec="apc")
#tfidfMat = weightTfIdf(docTermMat,normalize = TRUE)
#find the tokens/columns of the DTM that contain the keywords
locTok = sapply(keywords, function(x) colnames(docTermMat)[grepl(tolower(x),colnames(docTermMat))])
#locTok = sapply(keywords, function(x) colnames(docTermMat)[which(tolower(x) %in% colnames(docTermMat))])
locTok = as.character(c(unlist(locTok)))
tokCol = c(which(colnames(docTermMat) %in% locTok))
docMatLen = length(tokCol)
#compute tfidf score for each document
docScoreMatches = apply(tfidfMat[,tokCol],1,function(x) sum(x) )
docScoreNonMatches = apply(tfidfMat[,-tokCol],1,function(x) sum(x) )
docScore = 5 * docMatLen +  2 * docScoreMatches - docScoreNonMatches;
docRank = sort(docScore,decreasing=TRUE)
#return top ten scoring documents
return(docRank[1:10])
}
questionAnswer <- function(query) {
#note corp and dtm are global
keys = getKeywords(query)
type = getQueryType(query)
cat("\n")
cat(c("Query Keywords:", paste(keys, sep=", ")),"\n")
keys = augKey(keys,type)
cat("Retrieving Documents\n")
docs = getDocuments(keys,dtm)
cat("Scoring Documents with SMART TF-IDF\n")
topDocs = scoreDocuments(keys,DocumentTermMatrix(corp[docs]))
cat("Retrieving Sentences\n")
sents = getSentences(corpSen[names(corpSen) %in% names(topDocs)])
sents = getSentenceMatches(sents,keys)
cat("Pruning Sentences by Type\n")
sents = pruneSent(sents, type)
sentCorpProc = getSentCorp(sents,TRUE)
sentCorp = getSentCorp(sents,FALSE)
cat("Scoring Sentences\n")
topSents = scoreSentences(keys,DocumentTermMatrix(sentCorpProc),sentCorp)
bestAns = sents[as.numeric(names(topSents[which(is.na(topSents)==FALSE)]))]
cat("The 10 best scoring answers (in descending order) are:\n")
cat("\n")
return(bestAns)
}
questionAnswer("what affects GDP?")
questionAnswer("what percentage change in GDP is associated with personal consumption")
questionAnswer("what percentage change in GDP is associated with exports")
questionAnswer("what percentage change in GDP is associated with federal defense spending")
questionAnswer("what percentage change in GDP is associated with federal defense spending growth")
# function to determine if there are any Named Entities of typeEnt in a sentence
isSentType <- function(text, typeEnt) {
#text is a sentence (character)
#typeEnt is  one of "location", "organization", "percentage", "person", "misc"
if (typeEnt != "misc") {
# Convert text to class String from package NLP
text <- as.String(text)
if ((typeEnt == "percentage") ){ # || (typeEnt == "organization")) {
en_ann <- Maxent_Entity_Annotator(language = "en", kind = typeEnt, probs = FALSE,model = NULL)
pipeline <- list(sent_token_annotator,word_token_annotator,en_ann)
## Need sentence and word token annotations.
a2 <- annotate(text, pipeline)
# Determine if there are any entities of this type in the sentence, return TRUE/FALSE
.jcall("java/lang/System", method = "gc")
return(("entity" %in% names(table(a2$type))) && grepl("GDP", text))
} else if ((typeEnt == "person") || (typeEnt == "organization")) {
return(grepl("[A-Z]+[a-z]*\ [A-Z]+[a-z]+[A-Z]*[a-z]*",text))
} else {
return(grepl("GDP",text) || grepl("gdp",text))
}
} else {
return(TRUE)
}
# Extract entities
#sent <- text[a2[a2$type == "entity"]]
#sent = as.character(sent)
#return(sent)
}
questionAnswer("what percentage change in GDP is associated with federal defense spending")
questionAnswer("what percentage change in GDP is associated with federal defense spending growth")
questionAnswer("what percentage change in GDP is associated with nonfarm private inventories")
questionAnswer("what affects GDP?")
isSentType("The biggest factors weighing on growth were nonfarm private inventories, which subtracted 1.70 percentage points from GDP growth, and federal defense spending, which subtracted 1.28 percentage points.","percentage")
isSentType <- function(text, typeEnt) {
#text is a sentence (character)
#typeEnt is  one of "location", "organization", "percentage", "person", "misc"
if (typeEnt != "misc") {
# Convert text to class String from package NLP
text <- as.String(text)
if ((typeEnt == "percentage") ){ # || (typeEnt == "organization")) {
en_ann <- Maxent_Entity_Annotator(language = "en", kind = typeEnt, probs = FALSE,model = NULL)
pipeline <- list(sent_token_annotator,word_token_annotator,en_ann)
## Need sentence and word token annotations.
a2 <- annotate(text, pipeline)
# Determine if there are any entities of this type in the sentence, return TRUE/FALSE
.jcall("java/lang/System", method = "gc")
return((("entity" %in% names(table(a2$type))) || grepl("percentage",text)) && grepl("GDP", text))
} else if ((typeEnt == "person") || (typeEnt == "organization")) {
return(grepl("[A-Z]+[a-z]*\ [A-Z]+[a-z]+[A-Z]*[a-z]*",text))
} else {
return(grepl("GDP",text) || grepl("gdp",text))
}
} else {
return(TRUE)
}
# Extract entities
#sent <- text[a2[a2$type == "entity"]]
#sent = as.character(sent)
#return(sent)
}
isSentType("The biggest factors weighing on growth were nonfarm private inventories, which subtracted 1.70 percentage points from GDP growth, and federal defense spending, which subtracted 1.28 percentage points.","percentage")
questionAnswer("what percentage change in GDP is associated with federal defense spending")
# function to determine if there are any Named Entities of typeEnt in a sentence
isSentType <- function(text, typeEnt) {
#text is a sentence (character)
#typeEnt is  one of "location", "organization", "percentage", "person", "misc"
if (typeEnt != "misc") {
# Convert text to class String from package NLP
text <- as.String(text)
if ((typeEnt == "percentage") ){ # || (typeEnt == "organization")) {
en_ann <- Maxent_Entity_Annotator(language = "en", kind = typeEnt, probs = FALSE,model = NULL)
pipeline <- list(sent_token_annotator,word_token_annotator,en_ann)
## Need sentence and word token annotations.
a2 <- annotate(text, pipeline)
# Determine if there are any entities of this type in the sentence, return TRUE/FALSE
.jcall("java/lang/System", method = "gc")
return((("entity" %in% names(table(a2$type)))) && grepl("GDP", text))
} else if ((typeEnt == "person") || (typeEnt == "organization")) {
return(grepl("[A-Z]+[a-z]*\ [A-Z]+[a-z]+[A-Z]*[a-z]*",text))
} else {
return(grepl("GDP",text) || grepl("gdp",text))
}
} else {
return(TRUE)
}
# Extract entities
#sent <- text[a2[a2$type == "entity"]]
#sent = as.character(sent)
#return(sent)
}
# function to determine if there are any Named Entities of typeEnt in a sentence
isSentType <- function(text, typeEnt) {
#text is a sentence (character)
#typeEnt is  one of "location", "organization", "percentage", "person", "misc"
if (typeEnt != "misc") {
# Convert text to class String from package NLP
text <- as.String(text)
if ((typeEnt == "percentage") ){ # || (typeEnt == "organization")) {
en_ann <- Maxent_Entity_Annotator(language = "en", kind = typeEnt, probs = FALSE,model = NULL)
pipeline <- list(sent_token_annotator,word_token_annotator,en_ann)
## Need sentence and word token annotations.
a2 <- annotate(text, pipeline)
# Determine if there are any entities of this type in the sentence, return TRUE/FALSE
.jcall("java/lang/System", method = "gc")
return((("entity" %in% names(table(a2$type))) || grepl("percentage point",text)) && grepl("GDP", text))
} else if ((typeEnt == "person") || (typeEnt == "organization")) {
return(grepl("[A-Z]+[a-z]*\ [A-Z]+[a-z]+[A-Z]*[a-z]*",text))
} else {
return(grepl("GDP",text) || grepl("gdp",text))
}
} else {
return(TRUE)
}
# Extract entities
#sent <- text[a2[a2$type == "entity"]]
#sent = as.character(sent)
#return(sent)
}
questionAnswer("what percentage change in GDP growth is associated with federal defense spending")
questionAnswer("what companies went bankrupt in December 2013?")
questionAnswer("what companies went bankrupt in June 2014?")
questionAnswer("what companies filed for bankruptcy in July 2013?")
questionAnswer("what companies filed for bankruptcy in May 2012?")
questionAnswer("what companies filed for bankruptcy in March 2012?")
questionAnswer("what companies filed for bankruptcy in September 2014?")
questionAnswer("what companies filed for bankruptcy in September 2013?")
questionAnswer("what companies filed for bankruptcy in November 2013?")
questionAnswer("what companies filed for bankruptcy in Nov 2013?")
questionAnswer("what companies filed for bankruptcy in Jan 2011?")
questionAnswer("what companies filed for bankruptcy in Feb 2011?")
questionAnswer("what companies filed for bankruptcy in Oct 2014?")
questionAnswer("what companies filed for bankruptcy in Oct 2014 case?")
questionAnswer("what companies filed for bankruptcy in September 2014 case?")
# function to add additional keywords based on question type for more robust answers
augKey <- function(keys, type) {
#initialize return variable
finalKeys = keys
if (type == "gdp") {
finalKeys = c(finalKeys, "factors", "components", "%", "percent", "growth")
} else if (type == "organization") {
finalKeys = c(finalKeys, "case")
}
return(finalKeys)
}
questionAnswer("what companies filed for bankruptcy in September 2008?")
questionAnswer("what companies filed for bankruptcy in November 2011?")
keys
keys[4]
substr(keys[4],3,4)
# function to add additional keywords based on question type for more robust answers
augKey <- function(keys, type) {
#initialize return variable
finalKeys = keys
if (type == "gdp") {
finalKeys = c(finalKeys, "factors", "components", "%", "percent", "growth")
} else if (type == "organization") {
if (substr(keys[4],1,2)=="20") {
prefix = paste(substr(keys[4],3,4),"1",sep="-")
finalKeys = c(finalKeys, "case", prefix)
}
finalKeys = c(finalKeys, "case")
}
return(finalKeys)
}
questionAnswer("what companies filed for bankruptcy in September 2008?")
augKey(keys,"organization")
wordStem("08-1")
x = augKey(keys,"organization")
countMatches("The main bankruptcy case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555.",x)
countMatches("The main bankrupt case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555.",x)
countMatches("The main bankrupt case is In re: Lehman Brothers Holdings Inc in the same court, No. 09-13555.",x)
countMatches("The main bankrupt case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555.",x)
sum(grepl(x,"The main bankruptcy case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555."))
sum(grepl(x[5],"The main bankruptcy case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555."))
sum(grepl(x[4],"The main bankruptcy case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555."))
sum(grepl(x[6],"The main bankruptcy case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555."))
?grepl
countCont <- function(sentence, keywords) {
#stem the keywords
keywords = wordStem(tolower(keywords))
#check if the keywords are in the sentence, take sum
mts = lapply(keywords,grepl,x=sentence)
return(sum(mts))
}
countCont("The main bankrupt case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555.",x)
countCont <- function(sentence, keywords) {
#stem the keywords
keywords = wordStem(tolower(keywords))
#check if the keywords are in the sentence, take sum
mts = lapply(keywords,grepl,x=sentence)
return(sum(unlist(mts)))
}
countCont("The main bankrupt case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555.",x)
x
x
# function to add additional keywords based on question type for more robust answers
augKey <- function(keys, type) {
#initialize return variable
finalKeys = keys
if (type == "gdp") {
finalKeys = c(finalKeys, "factors", "components", "%", "percent", "growth")
} else if (type == "organization") {
if (substr(keys[4],1,2)=="20") {
prefix = paste(substr(keys[4],3,4),"1",sep="-")
finalKeys = c(finalKeys, "case", prefix)
} else {
finalKeys = c(finalKeys, "case")
}
}
return(finalKeys)
}
x = augKey(keys,"organization")
x
countCont("The main bankrupt case is In re: Lehman Brothers Holdings Inc in the same court, No. 08-13555.",x)
# function to score sentences
scoreSentences <- function(keywords, docTermMat, cleanCorp) {
#stem the keywords
keywords = wordStem(keywords)
#compute number of shared tokens
#find tokens that are not count = 0 in each document
#sentTerms = apply(docTermMat,1, function(x) colnames(x)[which(!x == 0)])
#give tfidf weightings
tfidfMat = weightSMART(docTermMat,spec="apc")
#tfidfMat = weightTfIdf(docTermMat,normalize = TRUE)
#find the tokens/columns of the DTM that contain the keywords
locTok = sapply(keywords, function(x) colnames(docTermMat)[grepl(tolower(x),colnames(docTermMat))])
#locTok = sapply(keywords, function(x) colnames(docTermMat)[which(tolower(x) %in% colnames(docTermMat))])
locTok = as.character(c(unlist(locTok)))
tokCol = c(which(colnames(docTermMat) %in% locTok))
docMatLen = sapply(cleanCorp, countCont, keywords=keywords)
#compute tfidf score for each document
docScoreMatches = apply(tfidfMat[,tokCol],1,function(x) sum(x) )
docScoreNonMatches = apply(tfidfMat[,-tokCol],1,function(x) sum(x) )
docScore = 5 * docMatLen +  2 * docScoreMatches - docScoreNonMatches;
docRank = sort(docScore,decreasing=TRUE)
#return top ten scoring documents
return(docRank[1:10])
}
questionAnswer("what companies filed for bankruptcy in September 2008?")
questionAnswer("what companies filed for bankruptcy in November 2011?")
questionAnswer("what companies filed for bankruptcy in October 2011?")
questionAnswer("what companies filed for bankruptcy in September 2008?")
questionAnswer("what companies filed for bankruptcy in September 2014?")
questionAnswer("Who is the CEO of Tesla?")
questionAnswer("Who is the CEO of Apple?")
questionAnswer("Who is the CEO of Facebook?")
questionAnswer("Who is the CEO of Microsoft?")
questionAnswer("What affects GDP?")
questionAnswer("What percent change in GDP is personal consumption associated with??")
questionAnswer("What percent change in GDP is associated with exports?")
questionAnswer("What percent change in GDP is associated with exports?")
countCont("Words go here", c("not", "a", "match"))
# function to score sentences
scoreSentences <- function(keywords, docTermMat, cleanCorp) {
#stem the keywords
keywords = wordStem(keywords)
#compute number of shared tokens
#find tokens that are not count = 0 in each document
#sentTerms = apply(docTermMat,1, function(x) colnames(x)[which(!x == 0)])
#give tfidf weightings
tfidfMat = weightSMART(docTermMat,spec="apc")
#tfidfMat = weightTfIdf(docTermMat,normalize = TRUE)
#find the tokens/columns of the DTM that contain the keywords
locTok = sapply(keywords, function(x) colnames(docTermMat)[grepl(tolower(x),colnames(docTermMat))])
#locTok = sapply(keywords, function(x) colnames(docTermMat)[which(tolower(x) %in% colnames(docTermMat))])
locTok = as.character(c(unlist(locTok)))
tokCol = c(which(colnames(docTermMat) %in% locTok))
#docMatLen = sapply(cleanCorp, countCont, keywords=keywords)
docMatLen = 1
#compute tfidf score for each document
docScoreMatches = apply(tfidfMat[,tokCol],1,function(x) sum(x) )
docScoreNonMatches = apply(tfidfMat[,-tokCol],1,function(x) sum(x) )
docScore = 5 * docMatLen +  2 * docScoreMatches - docScoreNonMatches;
docRank = sort(docScore,decreasing=TRUE)
#return top ten scoring documents
return(docRank[1:10])
}
questionAnswer("What percent change in GDP is associated with exports?")
# function to determine if there are any Named Entities of typeEnt in a sentence
isSentType <- function(text, typeEnt) {
#text is a sentence (character)
#typeEnt is  one of "location", "organization", "percentage", "person", "misc"
if (typeEnt != "misc") {
# Convert text to class String from package NLP
text <- as.String(text)
if ((typeEnt == "percentage") ){
en_ann <- Maxent_Entity_Annotator(language = "en", kind = typeEnt, probs = FALSE,model = NULL)
pipeline <- list(sent_token_annotator,word_token_annotator,en_ann)
## Need sentence and word token annotations.
a2 <- annotate(text, pipeline)
# Determine if there are any entities of this type in the sentence, return TRUE/FALSE
.jcall("java/lang/System", method = "gc")
return((("entity" %in% names(table(a2$type))) || grepl("percentage point",text)))# && grepl("GDP", text))
} else if ((typeEnt == "person") || (typeEnt == "organization")) {
return(grepl("[A-Z]+[a-z]*\ [A-Z]+[a-z]+[A-Z]*[a-z]*",text))
} else {
return(grepl("GDP",text) || grepl("gdp",text))
}
} else {
return(TRUE)
}
# Extract entities
#sent <- text[a2[a2$type == "entity"]]
#sent = as.character(sent)
#return(sent)
}
questionAnswer("What percent change in GDP is associated with exports?")
questionAnswer("What percent change in GDP is personal consumption associated with??")
# function to score sentences
scoreSentences <- function(keywords, docTermMat, cleanCorp) {
#stem the keywords
keywords = wordStem(keywords)
#compute number of shared tokens
#find tokens that are not count = 0 in each document
#sentTerms = apply(docTermMat,1, function(x) colnames(x)[which(!x == 0)])
#give tfidf weightings
tfidfMat = weightSMART(docTermMat,spec="apc")
#tfidfMat = weightTfIdf(docTermMat,normalize = TRUE)
#find the tokens/columns of the DTM that contain the keywords
locTok = sapply(keywords, function(x) colnames(docTermMat)[grepl(tolower(x),colnames(docTermMat))])
#locTok = sapply(keywords, function(x) colnames(docTermMat)[which(tolower(x) %in% colnames(docTermMat))])
locTok = as.character(c(unlist(locTok)))
tokCol = c(which(colnames(docTermMat) %in% locTok))
docMatLen = sapply(cleanCorp, countCont, keywords=keywords)
#compute tfidf score for each document
docScoreMatches = apply(tfidfMat[,tokCol],1,function(x) sum(x) )
docScoreNonMatches = apply(tfidfMat[,-tokCol],1,function(x) sum(x) )
docScore = 5 * docMatLen +  2 * docScoreMatches - docScoreNonMatches;
docRank = sort(docScore,decreasing=TRUE)
#return top ten scoring documents
return(docRank[1:10])
}
questionAnswer <- function(query) {
#note corp and dtm are global
keys = getKeywords(query)
type = getQueryType(query)
cat("\n")
cat(c("Query Type:",type,"\n"))
cat(c("Query Keywords:", paste(keys, sep=", ")),"\n")
keys = augKey(keys,type)
cat("Retrieving Documents\n")
docs = getDocuments(keys,dtm)
cat("Scoring Documents with SMART TF-IDF\n")
topDocs = scoreDocuments(keys,DocumentTermMatrix(corp[docs]))
cat("Retrieving Sentences\n")
sents = getSentences(corpSen[names(corpSen) %in% names(topDocs)])
sents = getSentenceMatches(sents,keys)
cat("Pruning Sentences by Type\n")
sents = pruneSent(sents, type)
sentCorpProc = getSentCorp(sents,TRUE)
sentCorp = getSentCorp(sents,FALSE)
cat("Scoring Sentences\n")
topSents = scoreSentences(keys,DocumentTermMatrix(sentCorpProc),sentCorp)
bestAns = sents[as.numeric(names(topSents[which(is.na(topSents)==FALSE)]))]
cat("The 10 best scoring answers (in descending order) are:\n")
cat("\n")
return(bestAns)
}
questionAnswer("What percent change in GDP is associated with federal defense spending?")
questionAnswer("What percent change in GDP is associated with exports?")
questionAnswer("What affects GDP?")
questionAnswer("What percentage is associated with exports")
# function to score sentences
scoreSentences <- function(keywords, docTermMat, cleanCorp) {
#stem the keywords
keywords = wordStem(keywords)
#compute number of shared tokens
#find tokens that are not count = 0 in each document
#sentTerms = apply(docTermMat,1, function(x) colnames(x)[which(!x == 0)])
#give tfidf weightings
tfidfMat = weightSMART(docTermMat,spec="apc")
#tfidfMat = weightTfIdf(docTermMat,normalize = TRUE)
#find the tokens/columns of the DTM that contain the keywords
locTok = sapply(keywords, function(x) colnames(docTermMat)[grepl(tolower(x),colnames(docTermMat))])
#locTok = sapply(keywords, function(x) colnames(docTermMat)[which(tolower(x) %in% colnames(docTermMat))])
locTok = as.character(c(unlist(locTok)))
tokCol = c(which(colnames(docTermMat) %in% locTok))
#error checking, ensure docMatLen is numeric even if NULL fcn call result
docMatLen = sapply(cleanCorp, countCont, keywords=keywords)
if (!is.numeric(docMatLen)) {
docMatLen = 1
}
#compute tfidf score for each document
docScoreMatches = apply(tfidfMat[,tokCol],1,function(x) sum(x) )
docScoreNonMatches = apply(tfidfMat[,-tokCol],1,function(x) sum(x) )
docScore = 5 * docMatLen +  2 * docScoreMatches - docScoreNonMatches;
docRank = sort(docScore,decreasing=TRUE)
#return top ten scoring documents
return(docRank[1:10])
}
questionAnswer("What percent change in GDP is associated with exports?")
# function to score and sort documents by TF-IDF on keywords
scoreDocuments <- function(keywords, redDocTermMat) {
#give SMART weightings
tfidfMat = weightSMART(redDocTermMat,spec="apc")
#tfidfMat = weightTfIdf(redDocTermMat,normalize=FALSE)
#stem the keywords
keywords = wordStem(keywords)
#find the tokens/columns of the DTM that contain the keywords
locTok = sapply(keywords, function(x) colnames(redDocTermMat)[grepl(tolower(x),colnames(redDocTermMat))])
locTok = as.character(c(unlist(locTok)))
tokCol = c(which(colnames(redDocTermMat) %in% locTok))
#compute tfidf score for each document
docScore = apply(tfidfMat[,tokCol],1,function(x) sum(x) )
docRank = sort(docScore,decreasing=TRUE)
#return top ten scoring documents
return(docRank[1:10])
}
